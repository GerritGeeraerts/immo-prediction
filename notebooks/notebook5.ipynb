{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-15T20:49:22.912005Z",
     "start_time": "2024-03-15T20:49:13.664987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88859, 45)\n",
      "(55251, 45)\n",
      "(45627, 45)\n",
      "       Bathroom Count  Bedroom Count  Habitable Surface  Land Surface  \\\n",
      "0                 1.0            4.0              180.0         360.0   \n",
      "1                 1.0            4.0              201.0         290.0   \n",
      "2                 1.0            5.0              196.0         357.0   \n",
      "3                 1.0            3.0              103.0           0.0   \n",
      "4                 1.0            2.0               71.0           0.0   \n",
      "...               ...            ...                ...           ...   \n",
      "36496             1.0            4.0              152.0          80.0   \n",
      "36497             1.0            3.0              172.0         382.0   \n",
      "36498             1.0            2.0               95.0           0.0   \n",
      "36499             1.0            3.0              308.0           0.0   \n",
      "36500             1.0            2.0              104.0           0.0   \n",
      "\n",
      "       Subtype  Latitude  Longitude  State of Building    EPC  Kitchen Type  \\\n",
      "0        100.0  0.628692   0.410596           0.666667  1.000           0.0   \n",
      "1        100.0  0.702479   0.489994           0.666667  0.625           1.0   \n",
      "2        200.0  0.589321   0.407362           0.000000  0.625           0.0   \n",
      "3          0.0  0.593052   0.790806           0.000000  0.875           0.0   \n",
      "4          0.0  0.438290   0.415995           0.666667  0.625           0.5   \n",
      "...        ...       ...        ...                ...    ...           ...   \n",
      "36496    100.0  0.614143   0.346731           0.333333  0.375           0.0   \n",
      "36497    100.0  0.516064   0.815738           0.000000  0.000           0.5   \n",
      "36498      0.0  0.611824   0.125481           0.666667  0.000           0.0   \n",
      "36499      0.0  0.455327   0.521088           0.000000  0.750           0.0   \n",
      "36500      0.0  0.616641   0.340989           0.666667  0.000           0.0   \n",
      "\n",
      "        Price  Building state price  Locality Typed Price  \n",
      "0      485000           2694.444444           2694.444444  \n",
      "1      399000           1985.074627           1985.074627  \n",
      "2      499000           2545.918367           2545.918367  \n",
      "3      180000           1747.572816           1747.572816  \n",
      "4      150000           2112.676056           2112.676056  \n",
      "...       ...                   ...                   ...  \n",
      "36496  365000           2401.315789           2401.315789  \n",
      "36497  320500           1863.372093           1863.372093  \n",
      "36498  296200           3117.894737           3117.894737  \n",
      "36499  189000            613.636364            613.636364  \n",
      "36500  695000           6682.692308           6682.692308  \n",
      "\n",
      "[36501 rows x 13 columns]\n",
      "      Bathroom Count  Bedroom Count  Habitable Surface  Land Surface  Subtype  \\\n",
      "0                1.0            1.0               36.0           0.0      0.0   \n",
      "1                4.0            5.0              790.0        3492.0    200.0   \n",
      "2                1.0            2.0              147.0           0.0      0.0   \n",
      "3                1.0            2.0               71.0           0.0      0.0   \n",
      "4                1.0            4.0              132.0         380.0    100.0   \n",
      "...              ...            ...                ...           ...      ...   \n",
      "9121             1.0            2.0               90.0           0.0      0.0   \n",
      "9122             1.0            2.0               63.0           0.0      0.0   \n",
      "9123             2.0            4.0              185.0         139.0    100.0   \n",
      "9124             2.0            2.0              176.0           0.0      0.0   \n",
      "9125             1.0            1.0               72.0           0.0      0.0   \n",
      "\n",
      "      Latitude  Longitude  State of Building    EPC  Kitchen Type  Price  \\\n",
      "0     0.569652   0.587088           0.666667  0.750           0.5    NaN   \n",
      "1     0.682717   0.529283           0.000000  0.750           0.0    NaN   \n",
      "2     0.692255   0.651199           1.000000  0.000           0.0    NaN   \n",
      "3     0.666624   0.138600           0.666667  0.000           0.0    NaN   \n",
      "4     0.626403   0.527041           0.000000  0.000           0.5    NaN   \n",
      "...        ...        ...                ...    ...           ...    ...   \n",
      "9121  0.562049   0.087466           0.666667  1.000           0.0    NaN   \n",
      "9122  0.654454   0.113030           0.000000  0.000           1.0    NaN   \n",
      "9123  0.638286   0.093556           0.666667  1.000           0.0    NaN   \n",
      "9124  0.681860   0.534020           0.833333  0.625           1.0    NaN   \n",
      "9125  0.582695   0.519900           1.000000  0.000           0.5    NaN   \n",
      "\n",
      "      Building state price  Locality Typed Price  \n",
      "0              2926.278392                   NaN  \n",
      "1              2805.228504                   NaN  \n",
      "2              3284.717215                   NaN  \n",
      "3              3919.960822                   NaN  \n",
      "4              2601.593869                   NaN  \n",
      "...                    ...                   ...  \n",
      "9121           5048.170186                   NaN  \n",
      "9122           4088.916521                   NaN  \n",
      "9123           2544.023448                   NaN  \n",
      "9124           4598.472912                   NaN  \n",
      "9125           3634.585979                   NaN  \n",
      "\n",
      "[9126 rows x 13 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 163\u001B[0m\n\u001B[1;32m    159\u001B[0m reg_model \u001B[38;5;241m=\u001B[39m LinearRegression()\n\u001B[1;32m    161\u001B[0m reg_model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m--> 163\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mreg_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# 5. Predict the target values for the testing data\u001B[39;00m\n\u001B[1;32m    166\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m reg_model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/base.py:848\u001B[0m, in \u001B[0;36mRegressorMixin.score\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001B[39;00m\n\u001B[1;32m    807\u001B[0m \n\u001B[1;32m    808\u001B[0m \u001B[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001B[39;00m\n\u001B[1;32m    844\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m r2_score\n\u001B[0;32m--> 848\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r2_score(y, y_pred, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:286\u001B[0m, in \u001B[0;36mLinearModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    273\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;124;03m    Predict using the linear model.\u001B[39;00m\n\u001B[1;32m    275\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;124;03m        Returns predicted values.\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 286\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:269\u001B[0m, in \u001B[0;36mLinearModel._decision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    267\u001B[0m     check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 269\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcoo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/base.py:633\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    631\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 633\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[1;32m    635\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1049\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1043\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1044\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1045\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m   1046\u001B[0m     )\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m-> 1049\u001B[0m     \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1050\u001B[0m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1051\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1052\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1053\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1054\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[1;32m   1057\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[1;32m   1058\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:126\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 126\u001B[0m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/immo-prediction/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:175\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    161\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    162\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    163\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    174\u001B[0m     )\n\u001B[0;32m--> 175\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "from features.generic_transformer import MyStandardScaler\n",
    "from features.genereric_build_features import OneHotEncodeColumns, PostalCodePimp\n",
    "from utils import save_model_as_pickle\n",
    "\n",
    "df = pd.read_csv('/home/gg/PycharmProjects/immo-prediction/data/raw/data.csv', low_memory=False)\n",
    "df.head()\n",
    "print(df.shape)\n",
    "\n",
    "sub_types_to_keep = [\n",
    "    'VILLA', 'HOUSE', 'APARTMENT',\n",
    "]\n",
    "columns_to_keep = ['Bathroom Count', 'Bedroom Count', 'Habitable Surface', 'Land Surface', 'Price', 'Subtype',\n",
    "                   'Latitude', 'Longitude', 'State of Building', 'EPC', 'Kitchen Type']\n",
    "\n",
    "# Fix some data in the dataframe\n",
    "df.loc[df['Subtype'] == 'APARTMENT', 'Land Surface'] = 0\n",
    "df = df.dropna(subset=['Bathroom Count', 'Bedroom Count', 'Habitable Surface', 'Subtype', 'Latitude', 'Longitude',])\n",
    "print(df.shape)\n",
    "# df = df[:50000)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df[df['Subtype'].isin(sub_types_to_keep)]\n",
    "print(df.shape)\n",
    "df = df[columns_to_keep]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "epc_map = {\n",
    "    \"A\": 7,\n",
    "    \"B\": 6,\n",
    "    \"C\": 5,\n",
    "    \"D\": 4,\n",
    "    \"E\": 3,\n",
    "    \"F\": 2,\n",
    "    \"G\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "def replace_value(x):\n",
    "    for k, v in epc_map.items():\n",
    "        if str(k) in str(x):\n",
    "            return v\n",
    "    return -1\n",
    "\n",
    "# the count of each value in EPC column\n",
    "df['EPC'] = df['EPC'].apply(replace_value)\n",
    "kitchen_map = {\n",
    "    \"INSTALLED\": 1,\n",
    "    \"HYPER_EQUIPPED\": 3,\n",
    "    \"SEMI_EQUIPPED\": 2,\n",
    "    \"USA_HYPER_EQUIPPED\": 3,\n",
    "    \"NOT_INSTALLED\": 0,\n",
    "    \"USA_INSTALLED\": 1,\n",
    "    \"USA_SEMI_EQUIPPED\": 2,\n",
    "    \"USA_UNINSTALLED\": 0,\n",
    "}\n",
    "df['Kitchen Type'] = df['Kitchen Type'].map(lambda x: kitchen_map.get(x, -1))\n",
    "state_map = {\n",
    "    \"AS_NEW\": 5,\n",
    "    \"JUST_RENOVATED\": 4,\n",
    "    \"GOOD\": 3,\n",
    "    \"TO_BE_DONE_UP\": 2,\n",
    "    \"TO_RENOVATE\": 1,\n",
    "    \"TO_RESTORE\": 0,\n",
    "}\n",
    "df['State of Building'] = df['State of Building'].map(lambda x: state_map.get(x, -1))\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X = df.drop(columns=['Price'])\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=41, test_size=0.2)\n",
    "\n",
    "# training data re-add the price column\n",
    "training_data = pd.concat([X_train, y_train], axis=1)\n",
    "training_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# testing data re-add the price column with np.nan\n",
    "testing_data = X_test.copy()\n",
    "testing_data['Price'] = np.nan\n",
    "testing_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ordinal_enc = OrdinalEncoder()\n",
    "training_data['Subtype'] = ordinal_enc.fit_transform(training_data[['Subtype']]) * 100\n",
    "testing_data['Subtype'] = ordinal_enc.transform(testing_data[['Subtype']]) * 100\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "training_data[['Longitude', 'Latitude', 'State of Building', 'EPC', 'Kitchen Type']] = min_max_scaler.fit_transform(\n",
    "    training_data[['Longitude', 'Latitude', 'State of Building', 'EPC', 'Kitchen Type']])\n",
    "testing_data[['Longitude', 'Latitude', 'State of Building', 'EPC', 'Kitchen Type']] = min_max_scaler.transform(\n",
    "    testing_data[['Longitude', 'Latitude', 'State of Building', 'EPC', 'Kitchen Type']])\n",
    "\n",
    "training_data['Building state price'] = training_data['Price'] / training_data['Habitable Surface']\n",
    "testing_data['Building state price'] = np.nan\n",
    "\n",
    "knn_bs_columns = ['Subtype', 'State of Building', 'EPC', 'Kitchen Type', 'Building state price']\n",
    "knn_bs = KNNImputer(n_neighbors=50)\n",
    "knn_bs.fit(training_data[knn_bs_columns])\n",
    "result_bs = knn_bs.transform(testing_data[knn_bs_columns])\n",
    "result_bs = pd.DataFrame(result_bs, columns=knn_bs_columns)\n",
    "testing_data['Building state price'] = result_bs['Building state price']\n",
    "columns_to_keep.append('Building state price')\n",
    "\n",
    "\n",
    "training_data['Locality Typed Price'] = training_data['Price'] / training_data['Habitable Surface']\n",
    "# in testing data create a new column with np.nan named 'Locality Typed Price'\n",
    "testing_data['Locality Typed Price'] = np.nan\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "\n",
    "# # use KNN to find the closest 5 neighbours\n",
    "# knn_columns = ['Longitude', 'Latitude', 'Subtype', 'Locality Typed Price']\n",
    "# knn = KNNImputer(n_neighbors=25)\n",
    "# knn.fit(training_data[knn_columns])\n",
    "# result = knn.transform(testing_data[knn_columns])\n",
    "# # create a new dataframe with the result\n",
    "# result = pd.DataFrame(result, columns=knn_columns)\n",
    "# # concatenate the result with the testing data\n",
    "# testing_data['Locality Typed Price'] = result['Locality Typed Price']\n",
    "# print(testing_data)\n",
    "# columns_to_keep.append('Locality Typed Price')\n",
    "\n",
    "\n",
    "\n",
    "# training_data.drop(columns=['Subtype'], inplace=True)\n",
    "# testing_data.drop(columns=['Subtype'], inplace=True)\n",
    "\n",
    "# one hot encode the subtype\n",
    "# OneHotEncodeColumns = OneHotEncodeColumns(['Subtype'])\n",
    "# training_data = OneHotEncodeColumns.fit_transform(training_data)\n",
    "# testing_data = OneHotEncodeColumns.transform(testing_data)\n",
    "\n",
    "\n",
    "# standard_scaler = MyStandardScaler(columns_to_scale=['Habitable Surface', 'Land Surface', 'Locality Typed Price', 'Building state price'])\n",
    "# \n",
    "# # training data\n",
    "# training_columns = training_data.columns\n",
    "# X_training = standard_scaler.fit_transform(training_data)\n",
    "# training_data = pd.DataFrame(X_training, columns=training_columns)\n",
    "# \n",
    "# # testing data\n",
    "# testing_columns = testing_data.columns\n",
    "# testing_data = standard_scaler.transform(testing_data)\n",
    "# testing_data = pd.DataFrame(testing_data, columns=testing_columns) # error\n",
    "\n",
    "# get the X_train and y_train\n",
    "X_train = training_data.drop(columns=['Price'])\n",
    "y_train = training_data['Price']\n",
    "\n",
    "# get the X_test and y_test\n",
    "X_test = testing_data.drop(columns=['Price'])\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "print(reg_model.score(X_test, y_test))\n",
    "\n",
    "# 5. Predict the target values for the testing data\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "# 6. Calculate the MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f'R-squared value: {r_squared:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Bathroom Count       0\nBedroom Count        0\nHabitable Surface    0\nLand Surface         0\nPrice                0\nSubtype              0\nLatitude             0\nLongitude            0\nState of Building    0\nEPC                  0\nKitchen Type         0\ndtype: int64"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# print correlation between columns_to_keep for the training data\n",
    "\n",
    "\n",
    "#sns.heatmap(df[columns_to_keep].corr(), annot=True)\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T20:48:25.755823Z",
     "start_time": "2024-03-15T20:48:25.750218Z"
    }
   },
   "id": "d3bf31f56f9bfa1c",
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
